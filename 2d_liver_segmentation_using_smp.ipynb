{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hyun-park/HW/blob/main/2d_liver_segmentation_using_smp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-45PyJG3FQu9"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQsbPR_ZCISb",
        "outputId": "c61f574d-5191-4bde-8d4d-3f322660c79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.2.1-py3-none-any.whl (88 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.11.1+cu111)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.10.0+cu111)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=2c9d60a18256cf618647eb797a01ae545c35bc8c138c216a936b507909ad1eaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=083cf42bef00be2f951b3a3102968ab8aabec956c229646afef191fd1cf45605\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5s6NzvZ8weiE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "import albumentations.pytorch\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import cv2 \n",
        "import nibabel as nib\n",
        "import segmentation_models_pytorch as smp\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PNUfYs9ZyAf8"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "\n",
        "lr = 0.001\n",
        "momentum = 0.99\n",
        "\n",
        "batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "epochs = 10\n",
        "log_interval = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8rdM6O4FGTg"
      },
      "source": [
        "# Load Data path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GsizlxU6WED1"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/Task03_Liver/Task03_Liver'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "klh2SPLUWDP8"
      },
      "outputs": [],
      "source": [
        "image_path =os.path.join(PATH+'/image.zip')\n",
        "mask_path = os.path.join(PATH+'/mask.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lYeO3E760d8Y"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(image_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/image')\n",
        "with zipfile.ZipFile(mask_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5DPtlCl57o3E"
      },
      "outputs": [],
      "source": [
        "image_path_list = glob('/content/image'+'/*')\n",
        "mask_path_list = glob('/content/mask'+'/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0xp79ELj7zzS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "train_path,test_path = train_test_split(image_path_list, test_size = 0.1, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AK6fjddW8Vko"
      },
      "outputs": [],
      "source": [
        "train_image_path = list()\n",
        "test_image_path = list()\n",
        "for i in train_path:\n",
        "  train_image_path_ = glob(i+'/*.png')\n",
        "  for path in train_image_path_:\n",
        "    train_image_path.append(path)\n",
        "for i in test_path:\n",
        "  test_image_path_ = glob(i +'/*.png')\n",
        "  for path in train_image_path_:\n",
        "    test_image_path.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kLcATbyNFP7",
        "outputId": "562beacb-403e-49fb-d4db-c9caad7a9c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "image = Image.open(train_image_path[0])\n",
        "image = np.array(image)\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfiaCyvhFJw3"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OiIy892x8agj"
      },
      "outputs": [],
      "source": [
        "class Train_Dataset(Dataset):\n",
        "    def __init__(self, data_path,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        img_name = path.split('/')[-1]\n",
        "        file_name = path.split('/')[-2]\n",
        "        one_mask_path =  '/content/mask/mask'+ '/' + file_name + '/'+ img_name\n",
        "        image = np.array(Image.open(path).resize((256,256)))\n",
        "        image = image[:,:,np.newaxis]/255\n",
        "        mask =  np.array(Image.open(one_mask_path).resize((256,256)))\n",
        "        mask[mask==2] = 1\n",
        "        mask = mask[...,np.newaxis]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D0oXQUy3xIFL"
      },
      "outputs": [],
      "source": [
        "class Test_Dataset(Dataset):\n",
        "    def __init__(self, data_path,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        img_name = path.split('/')[-1]\n",
        "        file_name = path.split('/')[-2]\n",
        "        one_mask_path = '/content/mask/mask' + '/' + file_name + '/'+img_name\n",
        "        image = np.array(Image.open(path).resize((256,256)))\n",
        "        image = image[:,:,np.newaxis]/255\n",
        "        mask =  np.array(Image.open(one_mask_path).resize((256,256)))\n",
        "        mask[mask==2] =1\n",
        "        mask = mask[...,np.newaxis]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vyIUlYyjEnlW"
      },
      "outputs": [],
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "     A.pytorch.transforms.ToTensor()\n",
        "     ]\n",
        "    )\n",
        "\n",
        "test_transform = A.Compose(\n",
        "    [\n",
        "     A.pytorch.transforms.ToTensor()\n",
        "     ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b51huAJsxnoC"
      },
      "outputs": [],
      "source": [
        "train_data = Train_Dataset(train_image_path,transform = train_transform)\n",
        "test_data = Test_Dataset(test_image_path,transform = test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZXLiye1mx6-o"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "        batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeggULvkFOXJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gaA9zOSDNEGv"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            #self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            #self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bLRRww8SFi4S"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/MyDrive/Task03_Liver/Task03_Liver/model\"\n",
        "###############################\n",
        "trial = 1\n",
        "n_epoches = 100\n",
        "LR = 0.001\n",
        "LR_DECREASE = 1e-5\n",
        "lr_decrease_epoch = 10\n",
        "BATCH_SIZE = 64\n",
        "patience= 15\n",
        "###############################\n",
        "ENCODER = 'resnet34'\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# create segmentation model with pretrained encoder\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER,\n",
        "    encoder_weights=None,\n",
        "    in_channels=1,\n",
        "    classes=1,\n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "\n",
        "loss = smp.utils.losses.DiceLoss()\n",
        "\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=LR),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jiScuGqBMqvs"
      },
      "outputs": [],
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "val_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "5EddajzCM4Gm",
        "outputId": "3cb4a45f-69fc-4da6-c244-c738e40c8543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "train:   0%|          | 0/1591 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4c0a56073ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nEpoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/utils/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# update loss logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/utils/train.py\u001b[0m in \u001b[0;36mbatch_update\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/utils/losses.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pr, y_gt)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mignore_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/utils/functional.py\u001b[0m in \u001b[0;36mf_score\u001b[0;34m(pr, gt, beta, eps, threshold, ignore_channels)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 GiB (GPU 0; 15.90 GiB total capacity; 2.98 GiB already allocated; 11.85 GiB free; 3.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "max_score = 0\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "for epoch in range(0, n_epoches):\n",
        "    \n",
        "    print(f'\\nEpoch: {epoch}')\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = val_epoch.run(test_loader)\n",
        "    \n",
        "    with open(os.path.join(save_path, f'results{str(trial).zfill(2)}.csv'), 'a') as f:\n",
        "            f.write('%03d,%0.6f,%0.6f,%0.6f,%0.6f\\n' % (\n",
        "                (epoch + 1),\n",
        "                train_logs['dice_loss'],\n",
        "                train_logs['iou_score'],\n",
        "                valid_logs['dice_loss'],\n",
        "                valid_logs['iou_score'],\n",
        "            ))\n",
        "    \n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']:\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, os.path.join(save_path, f'best_model{str(trial).zfill(2)}.pth'))\n",
        "        print('New Record!')\n",
        "        \n",
        "    torch.save(model, os.path.join(save_path, f'final_model{str(trial).zfill(2)}.pth'))\n",
        "    \n",
        "    early_stopping(valid_logs['dice_loss'], model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "    if epoch == lr_decrease_epoch:\n",
        "        optimizer.param_groups[0]['lr'] = LR_DECREASE\n",
        "        print(f'Decrease decoder learning rate to {LR_DECREASE}!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZDbeSHB2C9_"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc) \n",
        "plt.title('U-Net Model Accuracy', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Accuaracy', fontsize = 15)\n",
        "plt.ylim(0.95,1)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNwwl2e_2DvH"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(loss_val)\n",
        "plt.title('U-Net Model Loss', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Loss', fontsize = 15)\n",
        "plt.ylim(0,0.2)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qki13mi2EjL"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_dice)\n",
        "plt.plot(val_dice)\n",
        "plt.title('U-Net Model Dice Coef', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Dice', fontsize = 15)\n",
        "plt.ylim(0.6,1)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgdVpW9H6038"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDKcyCRA6sfd"
      },
      "outputs": [],
      "source": [
        "pred = F.softmax(test_masks_pred,dim = 1)\n",
        "prediction = torch.argmax(pred,dim = 1)\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB_3kfWIP7Pe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "for i in range(3):  \n",
        "  plt.subplot(3,1,i+1)\n",
        "  plt.imshow(prediction[i].cpu().data.numpy(),'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS5Cl4qn6rFi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "for i in range(3):  \n",
        "  plt.subplot(3,1,i+1)\n",
        "  plt.imshow(torch.squeeze(inputs_test[i]).cpu().data.numpy(),'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCu1cGrG7PBt"
      },
      "outputs": [],
      "source": [
        "inputs_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHHFy_sHTb9C"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "for i in range(3):  \n",
        "  plt.subplot(3,1,i+1)\n",
        "  plt.imshow(torch.squeeze(labels_test[i]).cpu().data.numpy(),'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0fAI0zkTvL8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2d_liver_segmentation_using_smp.ipynb",
      "provenance": [],
      "mount_file_id": "1qofQdaUz3ORjqDiTmoWHsqA82wwgaGa6",
      "authorship_tag": "ABX9TyPlZ996HbFX7ruz7QwwWIo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}